# Techniques used

## **1. Linear Regression**

### **üõ†Ô∏è Key Components and Techniques**

| Category | Technique Names |
| :--- | :--- |
| **Operation** | Regression |

---

### **üß∫ Data Preparation & Handling**

| Technique Names | Description / Purpose |
| :--- | :--- |
| SimpleImputer (Median) | Imputation |
| OneHotEncoder (`drop= 'first'` to avoid dummy variable trap) | Encoding |

---

### **üî¨ Preprocessing & Feature Engineering**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| StandardScaler | Scaling |
| RobustScaler | Scaling |
| Log Transformation | Transformation |
| Box - Cox Transformation | Transformation |
| PowerTransformer | Transformation |
| SelectKBest(f_Regression) | Selection |
| VarianceThreshold | Selection |

---

### **‚öôÔ∏è Training & Optimization**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| K - Fold Cross Validation (Shuffle = True) | Cross - Validation |
| Ridge(L2) | Regularization |
| Lasso(L1) | Regularization |
| ElasticNet | Regularization |
| GridSearch CV (`alpha`, `l1_ratio`) | Hyper Parameter Optimization |

---

### **üìä Evaluation & Metrics**

| Metric | Formula / Interpretation |
| :--- | :--- |
| RMSE (Root Mean Squared Error) | **Formula**: $\sqrt{\frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2}$. |
| MAE (Mean Absolute Error) | **Formula**: $\frac{1}{N} \sum_{i=1}^{N} |
| Adjusted $R^2$ | **Interpretation** Proportion of variance explained by the model, adjusted for the number of predictors. Prevents inflation of $R^2$ with extraneous features. |
| $R^2$ Score | **Formula**: $1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}$. **Interpretation**: Proportion of the variance in the dependent variable predictable by the model. Range $0$ to $1$. |
| Log Loss | **Formula**:$\frac{-1}{N} \sum_{i=1}^{N} [y_i \log(p_i) + (1 - y_i) \log(1 - p_i)]$. **Interpretation**: Penalizes confident incorrect predictions (even if not primary metric for LR). Lower is better. |

---

### **üìà Visualization & Interpretation**

#### **Diagnostic**
* Residual Plots (Homoscedasticity check)
* Q-Q Plots (Normality check)
#### **Interpretation**
* Coefficient Bar Charts (Weights)
* Predicted vs. Actual Scatter Plot
---

## **2. Logistic Regression**

### **üõ†Ô∏è Key Components and Techniques**

| Category | Technique Names |
| :--- | :--- |
| **Operation** | Classification |

---

### **üß∫ Data Preparation & Handling**

| Technique Names | Description / Purpose |
| :--- | :--- |
| SimpleImputer (Median / Mode strategy) | Imputation |
| OneHotEncoder (`handle_unknown ='ignore'`) | Encoding |
| LabelEncoder | Encoding |

---

### **üî¨ Preprocessing & Feature Engineering**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| StandardScaler | Scaling |
| Recursive Feature Elimination (RFE) | Selection |
| SelectFromModel | Selection | 

---

### **‚öôÔ∏è Training & Optimization**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| Stratified K - Fold | Cross - Validation |
| Class Weights ('balanced') | Imbalance |
| GridSearch CV (`C`, `penalty`, `solver`) | Hyper Parameter Optimization |

---

### **üìä Evaluation & Metrics**

| Metric | Formula / Interpretation |
| :--- | :--- |
| F1 - Score | **Formula**: $2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$. **Interpretation**: Harmonic mean of precision and recall. Useful for imbalanced classes. |
| ROC - AUC Score | **Interpretation**: Area Under the Receiver Operating Characteristic Curve. Measures the model's ability to distinguish between classes across all possible thresholds. Range $0.5$ to $1$. |
| Accuracy | **Formula**: $\frac{\text{True Positives} + \text{True Negatives}}{\text{Total Samples}}$. **Interpretation**: Ratio of correct predictions to the total number of predictions. |
| Log Loss | **Formula (Binary)**: $\frac{-1}{N} \sum_{i=1}^{N} [y_i \log(p_i) + (1 - y_i) \log(1 - p_i)]$. **Interpretation**: Measures the uncertainty of the probability predictions. Lower is better. |
| Precision - Recall Score | **Interpretation**: Measures trade-off between Precision (correct positive predictions) and Recall (correctly identified positives). |

---

### **üìà Visualization & Interpretation**

#### **Diagnostic**
* ROC Curve
* Precision - Recall Score
* Confusion Matrix
#### **Interpretation**
* Odds Ratio Plot (Exponentiated Coefficients)

---

## **3. Naive Bayes**

### **üõ†Ô∏è Key Components and Techniques**

| Category | Technique Names |
| :--- | :--- |
| **Operation** | Classification |

---

### **üß∫ Data Preparation & Handling**

| Technique Names | Description / Purpose |
| :--- | :--- |
| SimpleImputer (Mean for Gaussian, Mode for Categorical) | Imputation |
| OrdinalEncoder | Encoding (Categorical NB) |
| OneHotEncoder | Encoding (Multinomial NB) |
| StandardScaler | Scaling |
| MinMaxScaler | Scaling |
---

### **üî¨ Preprocessing & Feature Engineering**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| PowerTransformer (Yeo-Johnson for Gaussian assumption) | Transformation |
| SelectKBest (`chi2` or `mutual_info_classif`) | Selection |

---

### **‚öôÔ∏è Training & Optimization**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| Stratified K - Fold | Cross - Validation |
| Class Priors Adjustment | Imbalance |
| GridSearch CV (`var_smoothing` for Gaussian, `alpha` for multinomial) | Hyper Parameter Optimization |

---

### **üìä Evaluation & Metrics**

| Metric | Formula / Interpretation |
| :--- | :--- |
| Log Loss (Probabilistic Accuracy) | **Formula (Binary)**: $\frac{-1}{N} \sum_{i=1}^{N} [y_i \log(p_i) + (1 - y_i) \log(1 - p_i)]$. **Interpretation**: Measures how close the predicted probability is to the true value. Lower is better. |
| Accuracy | **Interpretation**: General measure of correctness. |
| F1 - Score | **Interpretation**: Harmonic mean of precision and recall. |
| Precision | **Formula**: $\frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$. **Interpretation**: Out of all positive predictions, how many were correct. |

---

### **üìà Visualization & Interpretation**

#### **Diagnostic**
* Confusion Matrix Heatmap
#### **Interpretation**
* Feature Distribution Histograms (per class)
* Feature Log- Probabilities

---

## **4. Random Forest**

### **üõ†Ô∏è Key Components and Techniques**

| Category | Technique Names |
| :--- | :--- |
| **Operation** | Classification &  Regression |

---

#### **üß∫ Data Preparation & Handling**

| Technique Names | Description / Purpose |
| :--- | :--- |
| SimpleImputer (Constant, Mean or Median) | Imputation |
| OrdinalEncoder | Encoding |
| OneHotEncoder | Encoding |

---

#### **üî¨ Preprocessing & Feature Engineering**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| SelectFromModel (Tree - based selection) | Selection |

---

#### **‚öôÔ∏è Training & Optimization**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| Stratified K - Fold (Classification) | Cross-Validation |
| K - Fold (Regression) | Cross- Validation |
| Class Weights (`balanced` or `balanced_subsample`) | Imbalance |
| Randomized Search CV (`n_estimators`, `max_depth`, `max_features`) | Hyper Parameter Optimization |

---

#### **üìä Evaluation & Metrics**

| Metric | Formula / Interpretation |
| :--- | :--- |
| F1 - Score | **Interpretation**: Harmonic mean of precision and recall (for classification). |
| RMSE (Root Mean Square Error) | **Formula**: $\sqrt{\frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2}$. **Interpretation**: Average magnitude of the errors in target units (for regression). |
| OOB Score (Out-of-Bag Error) | **Interpretation**: Internal estimate of generalization error. Calculated using samples not included in the bootstrap set for training a specific tree. |
---

#### **üìà Visualization & Interpretation**

##### **Diagnostic**
* Learning Curves
* ROC curves
##### **Interpretation**
* Feature Importance Plot (MDI or Permutation Importance)
* Tree Diagram (Single Estimator)

---

## **5. SVM**

### **üõ†Ô∏è Key Components and Techniques**

| Category | Technique Names |
| :--- | :--- |
| **Operation** | Classification & Regression |

---

#### **üß∫ Data Preparation & Handling**

| Technique Names | Description / Purpose |
| :--- | :--- |
| SimpleImputer (Median) | Imputation |
| OneHotEncoder | Encoding  |

---

#### **üî¨ Preprocessing & Feature Engineering**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| MinMaxScaler | Scaling |
| StandardScaler | Scaling |
| PCA (Principal Component Analysis) | Dimensionality Reduction |

---

#### **‚öôÔ∏è Training & Optimization**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| Stratified K-Fold | Cross - Validation |
| Class Wrights (`balanced`) | Imbalance |
| Randomized Search CV(`C`, `gamma`, `kernel`) | Hyper Parameter Optimization |

---

#### **üìä Evaluation & Metrics**

| Metric | Formula / Interpretation |
| :--- | :--- |
| Accuracy | **Interpretation**: General measure of correctness. |
| F1 - Score | **Interpretation**: Harmonic mean of precision and recall. |

---

#### **üìà Visualization & Interpretation**

##### Diagnostic
* Confusion Matrix
* Decision Boundary Plot (2D projection)

##### Interpretation:
* Inspection of Support Vectors

---

## **6. Decision Trees**

### üõ†Ô∏è **Key Components and Techniques**

| Category | Technique Names |
| :--- | :--- |
| **Operation** | Classification &  Regression |

---

#### **üß∫ Data Preparation & Handling**

| Technique Names | Description / Purpose |
| :--- | :--- |
| SimpleImputer (Mode / Median)| Imputation|
| OneHotEncoder | Encoding |
| OrdinalEncoder| Encoding |

---

#### **üî¨ Preprocessing & Feature Engineering**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| VarianceThreshold | Selection |
| SelectKBest | Selection |
---

#### **‚öôÔ∏è Training & Optimization**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
| Stratified K - Fold | Cross - Validation  |
| Cost-Complexity Pruning (CCP) | Optimization|
| GridSearchCV (`maxDepth`, `min_samples_split`, `min_samples_leaf`) | Hyper Parameter Optimization |

---

#### **üìä Evaluation & Metrics**

| Metric | Formula / Interpretation |
| :--- | :--- |
| Accuracy| **Interpretation**: General measure of correctness (for classification). |
| Root Mean Square Error | **Formula**: $\sqrt{\frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2}$. **Interpretation**: Average magnitude of the errors in target units (for regression). |
| Tree Depth | **Interpretation**: The length of the longest path from the root node to a leaf node. Indicator of model complexity. |
| Leaf Count | **Interpretation**: The total number of terminal nodes. Indicator of model complexity. | 
---

#### **üìà Visualization & Interpretation**

##### **Diagnostic**
* Validation Curve (Depth vs score)

##### **Interpretation**
* Graphviz Tree Diagram (Rule Visualization)
* Gini Importance Plot

--- 

## **7. K-Nearest Neighbors**

### **üõ†Ô∏è Key Components and Techniques**

| Category | Technique Names |
| :--- | :--- |
| **Operation** | Classification & Regression |

---

#### **üß∫ Data Preparation & Handling**

| Technique Names | Description / Purpose |
| :--- | :--- |
| SimpleImputer(Median) | Imputation |
| OneHotEncoder | Encoding |

---

#### **üî¨ Preprocessing & Feature Engineering**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
|MinMaxScaler | Scaling|
|StandardScaler |Scaling |
|PCA | Dimensionality Reduction (Essential for high dimensions)|
|NCA (Neighbor Components Analysis) | Dimensionality Reduction|

---

#### **‚öôÔ∏è Training & Optimization**

| Technique Names | Purpose / Parameters |
| :--- | :--- |
|Stratified K-Fold | Cross - Validation|
| Distance Weighting | Optimization |
| GridSearchCV |Hyper Parameter Optimization |
| Class adjustments | For classification |

---

#### **üìä Evaluation & Metrics**

| Metric | Formula / Interpretation |
| :--- | :--- |
| Accuracy | **Formula**: $\frac{1}{N} \sum_{i=1}^{N}. **Interpretation**: General measure of correctness (for classification) |
| MAE| **Formula**: $\frac{1}{N} \sum_{i=1}^{N} |
| Prediction Latency| **Interpretation**: The time taken for the model to make a prediction on a new sample (inference time). |

---

#### **üìà Visualization & Interpretation**

##### **Diagnostic**
* Elbow Method Plot (Error vs. K)
* Decision Boundary Plot

##### **Interpretation**
* Local Neighbor Inspection